#pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 playstation xboxone vulkan metal switch

// Generates large screen tiles in a fast, conservative manner.
#pragma kernel FillCoarseTiles     PASS = FILL_COARSE_TILES     COARSE_BINNING
// Removes certain entities from the coarse buffer at a large cost.
#pragma kernel PruneCoarseTiles    PASS = PRUNE_COARSE_TILES    COARSE_BINNING
// Generates small screen tiles in an accurate manner.
#pragma kernel FillFineTiles       PASS = FILL_FINE_TILES       FINE_BINNING

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition-config/Runtime/ShaderConfig.cs.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariablesGlobal.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/LightLoop/LightLoop.cs.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/LightLoop/TilingAndBinningUtilities.hlsl"

/* ------------------------------ Inputs ------------------------------------ */

#if (PASS == FILL_COARSE_TILES)
    // 1x list for all entites (sorted by category, we concatenate lists of all views).
    StructuredBuffer<float4> _xyBoundsBuffer : register(t0); // {x_min, x_max, y_min, y_max}
#endif

/* ------------------------------ Outputs ----------------------------------- */

#if (PASS == FILL_COARSE_TILES)
    // The tile buffer is composed of two parts:
    // the header (containing index ranges, 2 * sizeof(uint16)) and
    // the body (containing index lists, TiledLightingConstants.s_CoarseTileEntryLimit * sizeof(uint16)).
    // 1x list for all entites (sorted by category, we concatenate lists of all views).
    // The size of the buffer can be computed as follows:
    // DIV_ROUND_UP(RES_X, COARSE_TILE_SIZE) * DIV_ROUND_UP(RES_Y, COARSE_TILE_SIZE) *
    // BOUNDEDENTITYCATEGORY_COUNT * EYE_COUNT * (2 + COARSE_TILE_ENTRY_LIMIT) * 2 bytes per entry.
    // For example (1080p): 30 * 17 * 5 * 1 * (2 + 64) * 2 = 328.7 KiB.
    RWStructuredBuffer<uint> _CoarseTileBuffer : register(u0); // Index range + index list
#endif

#if (PASS == PRUNE_COARSE_TILES)
    // 1x list for all entites (sorted by category, we concatenate lists of all views).
    RWStructuredBuffer<uint> _DstCoarseTileBuffer : register(u0); // Index range + index list
#endif

#if (PASS == BUILD_FINE_TILES)
    // The tile buffer is composed of two parts:
    // the header (containing index ranges, 2 * sizeof(uint16)) and
    // the body (containing index lists, TiledLightingConstants.s_CoarseTileEntryLimit * sizeof(uint16)).
    // 1x list for all entites (sorted by category, we concatenate lists of all views).
    // The size of the buffer can be computed as follows:
    // DIV_ROUND_UP(RES_X, FINE_TILE_SIZE) * DIV_ROUND_UP(RES_Y, FINE_TILE_SIZE) *
    // BOUNDEDENTITYCATEGORY_COUNT * EYE_COUNT * (2 + FINE_TILE_ENTRY_LIMIT) * 2 bytes per entry.
    // For example (1080p): 240 * 165 * 5 * 1 * (2 + 16) * 2 = 6.8 MiB.
#endif

/* ------------------------------ Utilities --------------------------------- */

// Repackage to work around ridiculous constant buffer limitations of HLSL.
static uint s_BoundedEntityOffsetPerCategory[BOUNDEDENTITYCATEGORY_COUNT] = (uint[BOUNDEDENTITYCATEGORY_COUNT])_BoundedEntityOffsetPerCategory;
static uint s_BoundedEntityCountPerCategory[BOUNDEDENTITYCATEGORY_COUNT]  = (uint[BOUNDEDENTITYCATEGORY_COUNT])_BoundedEntityCountPerCategory;

/* ------------------------------ Implementation ---------------------------- */

#if (REMAINDER(TILE_ENTRY_LIMIT + 2, 2) != 0)
    #error "(TILE_ENTRY_LIMIT + 2) must be an integer multiple of 2."
#endif

#define THREADS_PER_GROUP (64)

[numthreads(THREADS_PER_GROUP, 1, 1)]
void FillCoarseTiles(uint threadID : SV_GroupIndex, uint3 groupID : SV_GroupID)
{
    // We could tile the threads in 8x8 blocks. The problem is,
    // the dimensions of the buffer are already quite small. The extra padding
    // (helper threads) required outweighs the benefits (improved locality, reduced divergence).
    const uint t   = threadID;
    const uint g   = groupID.x;
    const uint cat = groupID.y;
    const uint eye = groupID.z;

    const uint  globalTileIndex  = IndexFromCoordinate(uint2(t, g), THREADS_PER_GROUP);
    const uint  clampedTileIndex = min(globalTileIndex, TILE_BUFFER_DIMS.x * TILE_BUFFER_DIMS.y - 1);
    const uint2 clampedTileCoord = CoordinateFromIndex(clampedTileIndex, TILE_BUFFER_DIMS.x);

    // Helper threads may perform the same computation on valid data,
    // but do not store the results of the computation to memory.
    const bool isHelperThread = globalTileIndex != clampedTileIndex;

    if (isHelperThread) return; // Avoid adding too many checks or branches below

    // Entities are sorted by category.
    const uint entityIndex = s_BoundedEntityOffsetPerCategory[cat];
    const uint entityCount = s_BoundedEntityCountPerCategory[cat];

    const uint inputStart  = ComputeEntityBoundsBufferIndex(entityIndex, eye);
    const uint outputStart = ComputeTileBufferBodyIndex(clampedTileIndex, cat, eye);

    uint first = UINT16_MAX, last = 0;

    if (entityCount > 0) // Avoid wasted work
    {
        // Compute 2-D the AABB of the tile.
        const uint2  tileAaBbMinPtSS  = clampedTileCoord * TILE_SIZE;
        const uint2  tileAaBbMaxPtSS  = tileAaBbMinPtSS  + TILE_SIZE;                // (clampedTileCoord + 1) * TILE_SIZE
        const float2 tileAaBbMinPtNDC =          tileAaBbMinPtSS * _ScreenSize.zw;      // Divide
        const float2 tileAaBbMaxPtNDC = saturate(tileAaBbMaxPtSS * _ScreenSize.zw);     // Divide and clamp to the edge
        const float2 tileBoundsX      = float2(tileAaBbMinPtNDC.x, tileAaBbMaxPtNDC.x); // TODO: add epsilon for numerical robustness?
        const float2 tileBoundsY      = float2(tileAaBbMinPtNDC.y, tileAaBbMaxPtNDC.y); // TODO: add epsilon for numerical robustness?

        // Define inputs and outputs.
        uint i = 0, j = 0;
        uint indexPair = 0;

        // The algorithm is O(n * m) where 'n' is the entity count and 'm' is tile count.
        // Therefore, it will be slow if 'n' is large.
        // We should consider a sorting-based algorithm, which could be closer to O((n + m) * log(n)).
        // TODO: unroll.
        while ((i < entityCount) && (j < TILE_ENTRY_LIMIT))
        {
            float2 entityBoundsX = _xyBoundsBuffer[inputStart + i].xy;
            float2 entityBoundsY = _xyBoundsBuffer[inputStart + i].zw;

            if (IntervalsOverlap(entityBoundsX, tileBoundsX) &&
                IntervalsOverlap(entityBoundsY, tileBoundsY))
            {
                // We store intra-category indices.
                first = min(i, first);
                last  = max(i, last);

                // 2x 16-bit indices per uint.
                indexPair |= i << (16 * (j & 1)); // Order: first Lo, then Hi bits

                if ((j & 1) != 0) // Is the pair complete & ready to be stored?
                {
                    _CoarseTileBuffer[outputStart + (j / 2)] = indexPair;

                    indexPair = 0; // In order to use bitwise OR above
                }

                j++;
            }

            i++;
        }

        if (j < TILE_ENTRY_LIMIT)
        {
            i = UINT16_MAX; // Add a terminator

            indexPair |= i << (16 * (j & 1)); // Order: first Lo, then Hi bits

            _CoarseTileBuffer[outputStart + (j / 2)] = indexPair;
        }
    }

    uint outputRange = (last << 16) | first;

    // Store the metadata.
    uint headerIndex = ComputeTileBufferHeaderIndex(clampedTileIndex, cat, eye);
    _CoarseTileBuffer[headerIndex] = outputRange;
}

[numthreads(THREADS_PER_GROUP, 1, 1)]
void PruneCoarseTiles(uint threadID : SV_GroupIndex, uint3 groupID : SV_GroupID)
{

}

[numthreads(THREADS_PER_GROUP, 1, 1)]
void FillFineTiles(uint threadID : SV_GroupIndex, uint3 groupID : SV_GroupID)
{

}
